Top 10K Papers List

# [Papers]

+ Attention Is All You Need, https://arxiv.org/abs/1706.03762
+ BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, https://arxiv.org/abs/1810.04805
+ Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models, https://arxiv.org/abs/2304.01852
+ 
+ Natural Language Processing (almost) from Scratch, https://arxiv.org/abs/1103.0398, https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf
+ 
