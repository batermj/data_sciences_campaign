# References 

## Papers
+ Deep Learning papers reading roadmap for anyone who are eager to learn this amazing tech!  https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap

## Resources on Github
+ https://github.com/topics/deep-learning
+ Deep neural networks without the learning cliff! Classifiers and regressors compatible with scikit-learn., https://github.com/aigamedev/scikit-neuralnetwork
+ Distributed (Deep) Machine Learning Community, https://github.com/dmlc
+ Content consists of Jupyter Notebook tutorials walking through deep learning Frameworks (MXNet, Gluon) to Platforms (SageMaker, DeepLens) for common CV use-cases,https://github.com/aws-samples/aws-ml-vision-end2end
+ A curated list of awesome Deep Learning tutorials, projects and communities, https://github.com/ChristosChristofidis/awesome-deep-learning
+ A list of popular github projects related to deep learning, https://github.com/aymericdamien/TopDeepLearning
+ Top Deep Learning Projects based on their Stars!, https://github.com/hunkim/DeepLearningStars
+ Deep Learning Architecture Genealogy Project,https://github.com/hunkim/deep_architecture_genealogy
+ https://github.com/dennybritz?tab=repositories
+ Summaries and notes on Deep Learning research papers,https://github.com/dennybritz/deeplearning-papernotes
+ https://github.com/lisa-lab
+ https://github.com/ChristosChristofidis
+ https://github.com/zackchase
+ https://github.com/msracver
+ https://github.com/aws-samples

## CNN
+ A convolutional neural network that classifies sounds, https://github.com/awjuliani/sound-cnn
+ Deformable Convolutional Networks, https://github.com/msracver/Deformable-ConvNets
+ An mxnet implementation of Deconvolutional SSD, https://github.com/MTCloudVision/mxnet-dssd
+ CNN and LSTM model for text recognition, https://github.com/oyxhust/CNN-LSTM-CTC-text-recognition
+ The Places365-CNNs for Scene Classification http://places2.csail.mit.edu/, https://github.com/CSAILVision/places365

## Residual Neural Network
+ Reproduce ResNet-v2(Identity Mappings in Deep Residual Networks) with MXNet, https://github.com/tornadomeet/ResNet


## Recurrent Neural Network
+ Recurrent Neural Network - A curated list of resources dedicated to RNN, https://github.com/kjw0612/awesome-rnn
+ Multi-layer Recurrent Neural Networks (LSTM, RNN) for word-level language models in Python using TensorFlow, https://github.com/hunkim/word-rnn-tensorflow
+ A little library for text analysis with RNNs, https://github.com/IndicoDataSolutions/Passage

## Reinforcement Learning
+ Minimal Deep Q Learning (DQN & DDQN) implementations in Keras https://keon.io/deep-q-learning, https://github.com/keon/deep-q-learning
+ ReinforcementZeroToAll, https://github.com/hunkim/ReinforcementZeroToAll
+ Contains Jupyter notebooks associated with the "Deep Reinforcement Learning Tutorial" tutorial given at the O'Reilly 2017 NYC AI Conference, https://github.com/awjuliani/oreilly-rl-tutorial
+ Reinforcement Learning with Goals, https://github.com/awjuliani/dfp
+ Accompanying repository for Let's make a DQN / A3C series, https://github.com/jaara/AI-blog
+ Code for experiments with our RNN regularizer, which stochastically forces units to maintain previous values., https://github.com/teganmaharaj/zoneout
+ Reinforcement Learning Coach by Intel® AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms https://nervanasystems.github.io/coach/, https://github.com/NervanaSystems/coach


## GAN
+ This tutorial of GAN is Chinese translation of its English version which is created by MXNet group., https://github.com/wangx404/GAN_gluon_tutorials


## Meta Learning
+ Implementation of Meta-RL A3C algorithm, Implementation of Meta-RL A3C algorithm

## Bayesian Deep Learning

### Papers / Thesis
#### 2013: 
 1. Deep gaussian processes|Andreas C. Damianou,Neil D. Lawrence|2013 <br>
    Source: http://www.jmlr.org/proceedings/papers/v31/damianou13a.pdf

#### 2014: 
 1. Avoiding pathologies in very deep networks|D Duvenaud, O Rippel, R Adams|2014 <br>
    Source: http://www.jmlr.org/proceedings/papers/v33/duvenaud14.pdf
 2. Nested variational compression in deep Gaussian processes|J Hensman, ND Lawrence|2014
    Source: https://arxiv.org/abs/1412.1370

#### 2015: 
 1. On Modern Deep Learning and Variational Inference  |Yarin Gal, Zoubin Ghahramani|2015 <br>
    Source: http://www.approximateinference.org/accepted/GalGhahramani2015.pdf
 2. Rapid Prototyping of Probabilistic Models: Emerging Challenges in Variational Inference   |Yarin Gal, |2015<br>
    Source: http://www.approximateinference.org/accepted/Gal2015.pdf 
 3. Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference |Yarin Gal, Zoubin Ghahramani|2015<br>
    Source: http://arxiv.org/abs/1506.02158
 4. Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning  |Yarin Gal, Zoubin Ghahramani|2015<br>
    Source: http://arxiv.org/abs/1506.02142
 5. Dropout as a Bayesian Approximation: Insights and Applications     |Yarin Gal, |2015
    Source: https://sites.google.com/site/deeplearning2015/33.pdf?attredirects=0
 6. Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference |Yarin Gal, Zoubin Ghahramani|2015<br>
    Source: http://arxiv.org/abs/1506.02158
 7. Scalable Variational Gaussian Process Classification|J Hensman, AGG Matthews, Z Ghahramani|2015
    Source: http://www.jmlr.org/proceedings/papers/v38/hensman15.pdf
 
#### 2016:
 1. Relativistic Monte Carlo | Xiaoyu Lu| 2016 <br>
    Source: https://arxiv.org/abs/1609.04388
 2. Risk versus Uncertainty in Deep Learning: Bayes, Bootstrap and the Dangers of Dropout | Ian Osband| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_4.pdf
 3. Semi-supervised deep kernel learning|Neal Jean, Michael Xie, Stefano Ermon|2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_5.pdf
 4. Categorical Reparameterization with Gumbel-Softmax| Eric Jang, Shixiang Gu,Ben Poole| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_8.pdf
    Video: https://www.youtube.com/watch?v=JFgXEbgcT7g
 5. Learning to Optimise: Using Bayesian Deep Learning for Transfer Learning in Optimisation| Jonas Langhabel,   Jannik Wolff| 2016<br> 
    Source: http://bayesiandeeplearning.org/papers/BDL_9.pdf
 6. One-Shot Learning in Discriminative Neural Networks| Jordan Burgess,James Robert Lloyd,Zoubin Ghahramani| 2016<br>
    Source: http://bayesiandeeplearning.org/papers/BDL_10.pdf
 7. Distributed Bayesian Learning with Stochastic Natural-gradient Expectation Propagation| Leonard Hasenclever,
Stefan Webb| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_11.pdf
 8. Knots in random neural networks| Kevin K. Chen| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_2.pdf
 9. Discriminative Bayesian neural networks know what they do not know | Christian Leibig, Siegfried Wahl| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_12.pdf
 10. Variational Inference in Neural Networks using an Approximate Closed-Form Objective|Wolfgang Roth and Franz Pernkopf|2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_13.pdf
 11. Combining sequential deep learning and variational Bayes for semi-supervised inference| Jos van der Westhuizen, Dr. Joan Lasenby| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_14.pdf
 12. Importance Weighted Autoencoders with Random Neural Network Parameters| Daniel Hernández-Lobato,Thang D. Bui,Yinzhen Li| 2016 
Stefan Webb| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_15.pdf
 13. Variational Graph Auto-Encoders| Thomas N. Kipf,Max Welling| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_16.pdf
 14. Dropout-based Automatic Relevance Determination| Dmitry Molchanov, Arseniy Ashuha, Dmitry Vetrov| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_18.pdf
 15. Scalable GP-LSTMs with Semi-Stochastic Gradients| Maruan Al-Shedivat, Andrew Gordon Wilson, Yunus Saatchi, Zhiting Hu and Eric P. Xing| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_19.pdf
 16. Approximate Inference for Deep Latent Gaussian Mixture Models|Eric Nalisnick, Lars Hertel and Padhraic Smyth|2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_20.pdf
 17. Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Training | Dilin Wang, Yihao Feng and Qiang Liu| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_21.pdf 
    Video: https://www.youtube.com/watch?v=fi-UUQe2Pss
 18. Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks| Stefan Depeweg, José Miguel Hernández-Lobato, Finale Doshi-Velez and Steffen Udluft| 2016<br> 
    Source: https://arxiv.org/abs/1605.07127
 19. Accelerating Deep Gaussian Processes Inference with Arc-Cosine Kernels  | Kurt Cutajar, Edwin V. Bonilla, Pietro Michiardi and Maurizio Filippone| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_24.pdf
 20. Embedding Words as Distributions with a Bayesian Skip-gram Model | Arthur Bražinskas, Serhii Havrylov and Ivan Titov| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_25.pdf
 21. Variational Inference on Deep Exponential Family by using Variational Inferences on Conjugate Models|Mohammad Emtiyaz Khan and Wu Lin|2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_26.pdf
 22. Neural Variational Inference for Latent Dirichlet Allocation| Akash Srivastava and Charles Sutton| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_27.pdf
 23. Hierarchical Bayesian Neural Networks for Personalized Classification | Ajjen Joshi, Soumya Ghosh, Margrit Betke and Hanspeter Pfister| 2016<br> 
    Source: http://bayesiandeeplearning.org/papers/BDL_28.pdf
 24. Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles| Balaji Lakshminarayanan, Alexander Pritzel and Charles Blundell| 2016<br>
    Source: http://bayesiandeeplearning.org/papers/BDL_29.pdf
 25. Asynchronous Stochastic Gradient MCMC with Elastic Coupling| Jost Tobias Springenberg, Aaron Klein, Stefan Falkner and Frank Hutter| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_30.pdf
 26. The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables|Chris J. Maddison, Andriy Mnih and Yee Whye Teh| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_31.pdf
 27. Known Unknowns: Uncertainty Quality in Bayesian Neural Networks | Ramon Oliveira, Pedro Tabacof and Eduardo Valle| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_32.pdf
 28. Normalizing Flows on Riemannian Manifolds |Mevlana Gemici, Danilo Rezende and Shakir Mohamed|2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_33.pdf
 29. Posterior Distribution Analysis for Bayesian Inference in Neural Networks| Pavel Myshkov and Simon Julier| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_34.pdf
 30. Deep Bayesian Active Learning with Image Data| Yarin Gal, Riashat Islam and Zoubin Ghahramani| 2016<br> 
Stefan Webb| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_35.pdf
 31. Bottleneck Conditional Density Estimators|Rui Shu, Hung Bui and Mohammad Ghavamzadeh| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_36.pdf
 32. A Tighter Monte Carlo Objective with Renyi alpha-Divergence Measures| Stefan Webb and Yee Whye Teh| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_37.pdf
 33. Bayesian Neural Networks for Predicting Learning Curves| Aaron Klein, Stefan Falkner, Jost Tobias Springenberg and Frank Hutter| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_38.pdf
 34. Nested Compiled Inference for Hierarchical Reinforcement Learning|Tuan Anh Le, Atılım Güneş Baydin and Frank Wood|2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_41.pdf
 35. Open Problems for Online Bayesian Inference in Neural Networks | Robert Loftin and David Roberts| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_42.pdf
 36. Deep Probabilistic Programming| Dustin Tran, Matt Hoffman, Kevin Murphy, Rif Saurous, Eugene Brevdo, and David Blei| 2016<br> 
    Source: http://bayesiandeeplearning.org/papers/BDL_43.pdf
 37. Markov Chain Monte Carlo for Deep Latent Gaussian Models  |Matthew Hoffman| 2016 <br>
    Source: http://bayesiandeeplearning.org/papers/BDL_44.pdf
 38. Semi-supervised Active Learning with Deep Probabilistic Generative Models | Amar Shah and Zoubin Ghahramani| 2016<br> 
    Source: http://bayesiandeeplearning.org/papers/BDL_43.pdf
 39. Thesis: Uncertainty in Deep Learning  | Yarin Gal| PhD Thesis, 2016 <br>
    Source: http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf, Blog: http://mlg.eng.cam.ac.uk/yarin/blog_2248.html <br>
 40. Deep survival analysis|R. Ranganath, A. Perotte, N. Elhadad, and D. Blei|2016 <br>
    Source: http://www.cs.columbia.edu/~blei/papers/RanganathPerotteElhadadBlei2016.pdf
 41. Towards Bayesian Deep Learning: A Survey| Hao Wang, Dit-Yan Yeung|2016 <br>
    Source: https://arxiv.org/pdf/1604.01662
 #### 2017
 1.  Dropout Inference in Bayesian Neural Networks with Alpha-divergences |Yingzhen Li, Yarin Gal|2017 <br>
    Source: https://arxiv.org/abs/1703.02914
 2.  What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?  |Alex Kendall, Yarin Gal|2017 <br>
    Source: https://arxiv.org/abs/1703.04977

## Computer Vision
+ A curated list of deep learning resources for computer vision, https://github.com/kjw0612/awesome-deep-vision

## Natural Language Processing
+ Semantic Segmentation using Fully Convolutional Neural Network. https://github.com/upul/Semantic_Segmentation
+ A curated list of resources for text detection/recognition (optical character recognition ) with deep learning methods., https://github.com/hwalsuklee/awesome-deep-text-detection-recognition

## Deep-Learning-for-Recommendation-Systems
Deep Learning based Articles , Papers and Repositories for Recommendation Systems.

### Papers
1. Convolutional Matrix Factorization for Document Context-Aware Recommendation by Donghyun Kim, Chanyoung Park, Jinoh Oh, Seungyong Lee, Hwanjo Yu, RecSys 2016.<br>
Source: http://dm.postech.ac.kr/~cartopy/ConvMF/, Code: https://github.com/cartopy/ConvMF
2. A Neural Autoregressive Approach to Collaborative Filtering by Yin Zheng et all.<br>
Source: http://proceedings.mlr.press/v48/zheng16.pdf
3. Collaborative Recurrent Neural Networks for Dynamic Recommender Systems by Young-Jun Ko. ACML 2016 <br>
Source: http://proceedings.mlr.press/v63/ko101.pdf
4. Hybrid Recommender System based on Autoencoders by Florian Strub . 2016 <br>
Source: https://arxiv.org/pdf/1606.07659.pdf
5. Deep content-based music recommendation by Aaron van den Oord. <br>
Source: https://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf
6. DeepPlaylist: Using Recurrent Neural Networks to Predict Song Similarity by Anusha Balakrishnan. <br>
Source: https://cs224d.stanford.edu/reports/BalakrishnanDixit.pdf
7.  Hybrid music recommender using content-based and social information by  Paulo Chiliguano .<br>
Source: http://ieeexplore.ieee.org/document/7472151
8. CONTENT-AWARE COLLABORATIVE MUSIC RECOMMENDATION USING PRE-TRAINED NEURAL NETWORKS. <br>
Source: http://ismir2015.uma.es/articles/290_Paper.pdf
9.  TransNets: Learning to Transform for Recommendation  by Rose Catherine. <br>
Source: https://arxiv.org/abs/1704.02298 
10. Learning Distributed Representations from Reviews for Collaborative Filtering by  	Amjad Almahairi. <br> 	
Source: http://dl.acm.org/citation.cfm?id=2800192
11. Ask the GRU: Multi-task Learning for Deep Text Recommendations by T Bansal. <br> 
Source: https://arxiv.org/pdf/1609.02116.pdf
12.   A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems by Ali Mamdouh Elkahky.<br>
Source: http://sonyis.me/paperpdf/frp1159-songA-www-2015.pdf
13. Deep collaborative filtering via marginalized denoising auto-encoder by S Li.<br>
Source: https://pdfs.semanticscholar.org/ff29/2f00055d8221c42d4831679db9d3872b6fbd.pdf
14. Joint deep modeling of users and items using reviews for recommendation by L Zheng. <br>
Source: https://arxiv.org/pdf/1701.04783
15. Hybrid Collaborative Filtering with Neural Networks by Strub 
Source: https://pdfs.semanticscholar.org/fcbd/179590c30127cafbd00fd7087b47818406bc.pdf
16. Trust-aware Top-N Recommender Systems with Correlative Denoising Autoencoder by Y Pan. <br> 
Source: https://arxiv.org/pdf/1703.01760
17. Neural Semantic Personalized Ranking for item cold-start recommendation by T Ebesu . <br>
Source: http://www.cse.scu.edu/~yfang/NSPR.pdf
18. Representation Learning of Users and Items for Review Rating Prediction Using Attention-based Convolutional Neural Network by S Seo. <br> 
Source: http://mlrec.org/2017/papers/paper8.pdf
19. Collaborative Denoising Auto-Encoders for Top-N Recommender Systems by Y Wu. <br>
Source: http://alicezheng.org/papers/wsdm16-cdae.pdf, Code: https://github.com/jasonyaw/CDAE
20. Deep Neural Networks for YouTube Recommendations by Paul Covington. <br> 
Source: https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf
21. Wide & Deep Learning for Recommender Systems by Heng-Tze Cheng.<br>
Source: https://arxiv.org/abs/1606.07792
22. A Survey and Critique of Deep Learning on Recommender Systems by Lei Zheng.<br> 
Source: http://bdsc.lab.uic.edu/docs/survey-critique-deep.pdf
23. Restricted Boltzmann Machines for Collaborative Filtering by Ruslan Salakhutdinov. <br>
Source: http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf , Code: https://github.com/felipecruz/CFRBM
24. Meta-Prod2Vec - Product Embeddings Using Side-Information for Recommendation by Flavian Vasile. <br>
Source: https://arxiv.org/pdf/1607.07326.pdf
25.  Representation Learning and Pairwise Ranking for Implicit and Explicit Feedback in Recommendation Systems by Mikhail Trofimov <br>
Source: https://arxiv.org/abs/1705.00105
26. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. IJCAI2017 <br> Source:  https://arxiv.org/abs/1703.04247 , Code (provided by readers): https://github.com/Leavingseason/OpenLearning4DeepRecsys
27. Collaborative Filtering with Recurrent Neural Networks by Robin Devooght <br> Source:  https://arxiv.org/pdf/1608.07400.pdf
28. Training Deep AutoEncoders for Collaborative Filtering by Oleksii Kuchaiev, Boris Ginsburg. <br> Source: https://arxiv.org/abs/1708.01715 , Code: https://github.com/NVIDIA/DeepRecommender
29. Collaborative Variational Autoencoder for Recommender
Systems by Xiaopeng Li and James She <br> Source: http://eelxpeng.github.io/assets/paper/Collaborative_Variational_Autoencoder.pdf, Code: https://github.com/eelxpeng/CollaborativeVAE
30. Variational Autoencoders for Collaborative Filtering by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman and Tony Jebara <br> Source: https://arxiv.org/pdf/1802.05814.pdf, Code: https://github.com/dawenl/vae_cf
31. Neural Collaborative Filtering by Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu and Tat-Seng Chua <br> Source: https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf , Code : https://github.com/hexiangnan/neural_collaborative_filtering
 Source: https://arxiv.org/abs/1708.05031
 
### Blogs
1. Deep Learning Meets Recommendation Systems by Wann-Jiun. <br>
Source: https://blog.nycdatascience.com/student-works/deep-learning-meets-recommendation-systems/

### Workshops 
1. 2nd Workshop on Deep Learning for Recommender Systems , 27 August 2017. Como, Italy.<br> 
Source: http://dlrs-workshop.org

### Tutorials
1. Deep Learning for Recommender Systems by Balázs Hidasi. [RecSys Summer School](http://pro.unibz.it/projects/schoolrecsys17/program.html), 21-25 August, 2017, Bozen-Bolzano. [Slides](https://www.slideshare.net/balazshidasi/deep-learning-in-recommender-systems-recsys-summer-school-2017)
2. Deep Learning for Recommender Systems by Alexandros	Karatzoglou and Balázs	Hidasi. RecSys2017 Tutorial. [Slides](https://www.slideshare.net/kerveros99/deep-learning-for-recommender-systems-recsys2017-tutorial)
3. Introduction to recommender Systems by Miguel González-Fierro. [Link](https://github.com/miguelgfierro/sciblog_support/blob/master/Intro_to_Recommendation_Systems/Intro_Recommender.ipynb)
4. Collaborative Filtering using a RBM by Big Data University. [Link](https://github.com/santipuch590/deeplearning-tf/blob/master/dl_tf_BDU/4.RBM/ML0120EN-4.2-Review-CollaborativeFilteringwithRBM.ipynb)

### Software
1. Spotlight: deep learning recommender systems in PyTorch <br>
Source: https://github.com/maciejkula/spotlight

2. Amazon DSSTNE: deep learning library by amazon (specially for recommended systems i.e. sparse data) <br>
Source: https://github.com/amzn/amazon-dsstne

3. Recoder: Large scale training of factorization models for Collaborative Filtering with PyTorch <br>
Source: https://github.com/amoussawi/recoder

## Survial Analysis using Deep Learning
Bayesian Deep Learning based Articles , Papers and Repositories for Survival Analysis.

### Papers
1. Deep Survival Analysis by Rajesh Ranganath,Adler Perotte,David Blei et all. JMLR 2016<br>
Source: http://proceedings.mlr.press/v56/Ranganath16.pdf 
2. The Survival Filter: Joint Survival Analysis with a Latent Time Series by Rajesh Ranganath,Adler Perotte,David Blei et all. UAI, 2015<br>
Source: https://www.cs.princeton.edu/~rajeshr/papers/15uai.pdf
3. DeepSurv: Personalized Treatment Recommender System Using A Cox Proportional Hazards Deep Neural Network by Jared Katzman, Uri Shaham, Jonathan Bates, Alexander Cloninger, Tingting Jiang, Yuval Kluger . ACML 2016 <br>
Source: https://arxiv.org/abs/1606.00931
4. Deep Multi-task Gaussian Processes for
Survival Analysis with Competing Risks by Ahmed M. Alaa, Mihaela van der Schaar. NIPS 2017 <br>
Source: http://papers.nips.cc/paper/6827-deep-multi-task-gaussian-processes-for-survival-analysis-with-competing-risks.pdf
5. DeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks by Changhee Lee, William R. Zame, Jinsung Yoon, Mihaela van der Schaar. 2018 <br>
Source: http://medianetlab.ee.ucla.edu/papers/AAAI_2018_DeepHit.pdf 
6.  Deep Learning for Patient-Specific Kidney Graft Survival Analysis by Margaux Luck, Tristan Sylvain, Héloïse Cardinal, Andrea Lodi, Yoshua Bengio. 2017 <br>
Source: https://arxiv.org/abs/1705.10245
7.  WSISA: Making Survival Prediction from Whole Slide Histopathological Images by  Xinliang Zhu, Jiawen Yao, Feiyun Zhu, and Junzhou Huang. CVPR 2017<br>
Source: http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhu_WSISA_Making_Survival_CVPR_2017_paper.pdf
8. Deep Integrative Analysis for Survival Prediction by Chenglong Huang, Albert Zhang and Guanghua Xiao,Pacific Symposium on  Biocomputing  2018 . <br>
Source: https://pdfs.semanticscholar.org/3a9d/c97916ed05badf0e4c913bf293cbd9a4d82c.pdf
9.  Deep Correlational Learning for Survival Prediction from Multi-modality Data  by Jiawen Yao, Xinliang Zhu, Feiyun Zhu, Junzhou Huang.MICCAI 2017 <br>
Source: https://link.springer.com/chapter/10.1007/978-3-319-66185-8_46 
10. Deep convolutional neural network for survival analysis with pathological images by Xinliang Zhu, Jiawen Yao,Junzhou Huang. BIBM 2016  <br> Source: http://ieeexplore.ieee.org/abstract/document/7822579/
11. Predicting clinical outcomes from large scale cancer genomic profiles with deep survival models by S Yousefi, F Amrollahi, M Amgad, C Dong, JE Lewis… - Scientific Reports, 2017 - nature.com. <br> 
Source: https://www.nature.com/articles/s41598-017-11817-6
12. Combining Deep Learning and Survival Analysis for Asset Health
Management by Linxia Liao, Hyung-il Ahn. International Journal of Prognostics and Health Management, 2016<br>
Source: https://pdfs.semanticscholar.org/4974/0c7f9923425c4a2942c7e382beaf78cbd4fe.pdf
13. A Risk Stratification Model for Lung Cancer Based on Gene Coexpression Network and Deep Learning by Hongyoon Choi
,  Kwon Joong Na, BioMed Research International 2018.<br>
Source: http://downloads.hindawi.com/journals/bmri/aip/2914280.pdf
14.  Deep Neural Networks for Survival Analysis Based on a Multi-Task Framework by Stephane Fotso.2018 <br>
Source: https://arxiv.org/abs/1801.05512
15. Scalable Joint Models for Reliable
Uncertainty-Aware Event Prediction by Hossein Soleimani,  James Hensman,  and Suchi Saria. IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, 2017 <br>
Source: http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8013802
16. Application of random survival forests in understanding the determinants of under-five child mortality in Uganda in the presence of covariates that satisfy the proportional and non-proportional hazards assumption by Justine B. Nasejje, Henry Mwambi. BMC Research Notes 2017 <br> 
Source: https://bmcresnotes.biomedcentral.com/articles/10.1186/s13104-017-2775-6 <br>
17.Posterior Consistency for a Non-parametric Survival Model under a Gaussian Process Prior by Tamara Fernández, Yee Whye Teh . 2016 <br>
Source: https://arxiv.org/abs/1611.02335
18. A comparison of the conditional inference survival forest model to random survival forests based on a simulation study as well as on two applications with time-to-event data byJustine B. NasejjeEmail author, Henry Mwambi, Keertan Dheda and Maia Lesosky. BMC Medical Research MethodologyBMC series – open, inclusive and trusted 2017 <br> 
Source: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-017-0383-8
19. Gaussian Processes for Survival Analysis by Tamara Fernandez, Nicolas Rivera, Yee Whye Teh. NIPS 2016 <br>
Source: http://papers.nips.cc/paper/6443-gaussian-processes-for-survival-analysis.pdf
20. Deep Learning based multi-omics integration robustly predicts survival in liver cancer by Kumardeep Chaudhary, Olivier B Poirion, Liangqun Lu and Lana X Garmire. Clinical Cancer Research, 2018 <br> 
Source: http://clincancerres.aacrjournals.org/content/clincanres/early/2017/10/05/1078-0432.CCR-17-0853.full.pdf
21. Going Deep: The Role of Neural Networks for Renal Survival and Beyond by Amelia J.Averitt, Karthik Natarajan. Kidney International Reports, 2018 <br>
Source: https://www.sciencedirect.com/science/article/pii/S2468024917304771
22. 3D Deep Learning for Multi-modal Imaging-Guided Survival Time Prediction of Brain Tumor Patients by Dong Nie, Han Zhang, Ehsan Adeli, Luyan Liu, Dinggang Shen. MICCAI 2016<br> 
Source: https://link.springer.com/chapter/10.1007/978-3-319-46723-8_25
23. A Deep Learning-Based Radiomics Model for Prediction of Survival in Glioblastoma Multiforme by Jiangwei Lao, Yinsheng Chen, Zhi-Cheng Li, Qihua Li, Ji Zhang, Jing Liu & Guangtao Zhai. Scientific Reports, Nature 2017<br>
Source: https://www.nature.com/articles/s41598-017-10649-8
24. Neural Survival Recommender. WSDM 2017 <br>
Source: https://dl.acm.org/citation.cfm?id=3018719
25. Association of Pathological Fibrosis With Renal Survival Using Deep Neural Networks  by Vijaya B.Kolachalama, Vipul C.Chitalia et all.<br> Kidney International Reports, 2018
Source: https://www.sciencedirect.com/science/article/pii/S2468024917304370
26. Deep Recurrent Survival Analysis by Kan Ren, Jiarui Qin et al. AAAI 2019 <br>
Source: https://arxiv.org/abs/1809.02403
Code: https://github.com/rk2900/drsa


### Thesis 
1. Gaussian Process Based
Approaches for Survival Analysis , Alan D. Saul, University of Sheffield, UK. 2017<br> 
Source: http://etheses.whiterose.ac.uk/17946/1/thesis.pdf


### Software
1. DeepSurv: DeepSurv is a deep learning approach to survival analysis <br>
Source: https://github.com/jaredleekatzman/DeepSurv
Blogs
2. SurvivalNet: Deep learning survival models <br>
Source: https://github.com/CancerDataScience/SurvivalNet

## Auto Driving
+ Vehicle Detection Project, https://github.com/udacity/CarND-Vehicle-Detection
+ CarND-Advanced-Lane-Lines, https://github.com/udacity/CarND-Advanced-Lane-Lines
+ First Project Udacity's Self-Driving NanoDegree, https://github.com/upul/CarND-LaneLines-P1c
+ Third Project of the Udacity Self-Driving Car Nanodegree Program, https://github.com/upul/Behavioral-Cloning

## Deep Learning Projects
+ A list of popular github projects related to deep learning,https://github.com/aymericdamien/TopDeepLearning

## Frameworks, Library
+ Minimal Deep Learning library is written in Python/Cython/C++ and Numpy/CUDA/cuDNN. https://github.com/upul/Aurora

## Tensorflow
+ This repository contains code examples for the Stanford's course: TensorFlow for Deep Learning Research. http://cs20.stanford.edu, https://github.com/chiphuyen/stanford-tensorflow-tutorials
+ TensorFlow - A curated list of dedicated resources http://tensorflow.org, https://github.com/jtoy/awesome-tensorflow
+ This repository contains code examples for the Stanford's course: TensorFlow for Deep Learning Research. http://cs20.stanford.edu, https://github.com/chiphuyen/stanford-tensorflow-tutorials
+ Code for O'Reilly's "A Short Course on TensorFlow", https://github.com/chiphuyen/tf-oreilly
+ Repository for "Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python",https://github.com/rasbt/deep-learning-book
+ TensorFlow Basic Tutorial Labs, https://github.com/hunkim/DeepLearningZeroToAll
+ Multi-layer Recurrent Neural Networks (LSTM, RNN) for word-level language models in Python using TensorFlow,https://github.com/hunkim/word-rnn-tensorflow
+ Learning Machine Learning with TensorFlow, https://github.com/golbin/TensorFlow-ML-Exercises
+ TensorFlow tutorials and best practices. https://twitter.com/VahidK, https://github.com/vahidk/EffectiveTensorflow
+ MNIST with TensorFlow, https://github.com/golbin/TensorFlow-MNIST
+ A set of Deep Reinforcement Learning Agents implemented in Tensorflow, https://github.com/awjuliani/DeepRL-Agents
+ Accompanying notebook for the Entailment with Tensorflow article, https://github.com/Steven-Hewitt/Entailment-with-Tensorflow
+ A collection of deep learning tutorials using Tensorflow and Python, https://github.com/awjuliani/TF-Tutorials
+ Convolutional Neural Network for Text Classification in Tensorflow, https://github.com/dennybritz/cnn-text-classification-tf
+ A TensorFlow implementation of Baidu's DeepSpeech architecture, https://github.com/mozilla/DeepSpeech
+ Code for the book Deep Learning with PyTorch by Eli Stevens and Luca Antiga, https://github.com/deep-learning-with-pytorch/dlwpt-code, https://www.manning.com/books/deep-learning-with-pytorch

## MXNET
+ Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Scala, Go, Javascript and more https://mxnet.apache.org,https://github.com/apache/incubator-mxnet
+ An interactive book on deep learning. Much easy, so MXNet. Wow. http://gluon.mxnet.io, https://github.com/zackchase/mxnet-the-straight-dope
+ A curated list of MXNet examples, tutorials and blogs, https://github.com/chinakook/Awesome-MXNet
+ mobilenet-mxnet, https://github.com/KeyKy/mobilenet-mxnet
+ the implementation of MTCNN in MXnet, https://github.com/Seanlinx/mtcnn
+ MXNet port of SSD: Single Shot MultiBox Object Detector. Reimplementation of https://github.com/weiliu89/caffe/tree/ssd, MXNet port of SSD: Single Shot MultiBox Object Detector. Reimplementation of https://github.com/weiliu89/caffe/tree/ssd

## PyTorch
+ https://github.com/topics/pytorch
+ Simple PyTorch Tutorials Zero to ALL! , https://github.com/hunkim/PyTorchZeroToAll
+ PyTorch Tutorial for Deep Learning Researchers,https://github.com/yunjey/pytorch-tutorial
+ Yet another WaveNet implementation in PyTorch, https://github.com/golbin/WaveNet
+ Yet another Cycle GAN implementation in PyTorch, https://github.com/golbin/CycleGAN
+ A comprehensive list of pytorch related content on github,such as different models,implementations,helper libraries,tutorials etc.,https://github.com/bharathgs/Awesome-pytorch-list

## Keras
+ Keras Tuner documentation, https://keras-team.github.io/keras-tuner/

## MAX (Model Asset Exchange,MAE)
+ Model Asset eXchange: Path to Ubiquitous Deep Learning Deployment, https://arxiv.org/abs/1909.01606


## Theano
+ Deep Learning with Theano, published by Packt, https://github.com/PacktPublishing/Deep-Learning-with-Theano

## Deeplearning4J
+ https://github.com/deeplearning4j/dl4j-examples

## BigDL
+ https://software.intel.com/en-us/articles/building-large-scale-image-feature-extraction-with-bigdl-at-jdcom

## Face Detection and Recognition 
+ AIND-CV-FacialKeypoints, https://github.com/udacity/AIND-CV-FacialKeypoints
+ Detect and align faces in images using dlib and opencv, https://github.com/nlhkh/face-alignment-dlib
+ Face Recognition Project on MXNet, https://github.com/deepinsight/insightface
+ Using mxnet for face-related algorithm, https://github.com/tornadomeet/mxnet-face

## Object Recognition
+ mean Average Precision - This code evaluates the performance of your neural net for object recognition., https://github.com/Cartucho/mAP

## MISC
+ dlsys-course,https://github.com/dlsys-course
+ This repository contains code examples for the Stanford's course: TensorFlow for Deep Learning Research. http://cs20.stanford.edu,, https://github.com/chiphuyen/stanford-tensorflow-tutorials
+ Turn your two-bit doodles into fine artworks with deep neural networks, generate seamless textures from photos, transfer style from one image to another, perform example-based upscaling, but wait... there's more! (An implementation of Semantic Style Transfer.), https://github.com/alexjc/neural-doodle

## GPU
+ Acceleration package for neural networks on multi-core CPUs, https://github.com/Maratyszcza/NNPACK

## Neural Net Visualization
+ Neural network visualizer http://ethereon.github.io/netscope, https://github.com/ethereon/netscope

## Neural Network
+ ,https://github.com/topics/neural-network

## Benchmark
+ THE Deep Learning Benchmarks, https://github.com/DeepMark/deepmark
+ Easy benchmarking of all publicly accessible implementations of convnets, https://github.com/soumith/convnet-benchmarks


## Online Courses
+ Deep Learning Projects from Stanford's 230 class, https://web.stanford.edu/class/cs230/, http://cs230.stanford.edu/proj-spring-2018.html


## Sumer School
+ Summer School, https://github.com/mila-udem/summerschool2015

## NIPS Proceedings
+ https://papers.nips.cc/

## Deep Learning Problem
+ A living collection of deep learning problems https://openai.com/requests-for-research, https://github.com/openai/requests-for-research
